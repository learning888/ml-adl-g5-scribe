{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formas de preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sklearn.feature_extraction.text.CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/veterok/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = [\"No te me subas al coco no, No te me subas al coco no, No nena no al coco no al coco no\",\n",
    "       \"No no no al coco no al coco no, No no no al coco no al coco no, No te me subas al coco no, No te me subas al coco no, No nena no al coco no al coco no\",\n",
    "       \"No te me subas al coco no, No te me subas al cono no, No nena no al coco no al coco no\",\n",
    "       \"No no no al coco no al coco no, No no no al coco no al coco no, No te me subas al coco no, No te me subas al coco no, No nena no al coco no al coco no\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = CountVectorizer(max_features=3)\n",
    "letras = vectorize.fit_transform(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['al', 'coco', 'no']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  1,  8,  2],\n",
       "       [ 8,  0,  1, 18,  2],\n",
       "       [ 3,  1,  1,  8,  2],\n",
       "       [ 8,  0,  1, 18,  2]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letras.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = pd.DataFrame(letras.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df.columns = vectorize.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coco</th>\n",
       "      <th>cono</th>\n",
       "      <th>nena</th>\n",
       "      <th>no</th>\n",
       "      <th>subas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   coco  cono  nena  no  subas\n",
       "0     4     0     1   8      2\n",
       "1     8     0     1  18      2\n",
       "2     3     1     1   8      2\n",
       "3     8     0     1  18      2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sklearn.feature_extraction.text.TfidfVectorizer`\n",
    "\n",
    "Term Frequency Inverse Document Frequency: Mide la \"originalidad\" de una palabra mediante la comparación de la cantidad de veces que aparece una palabra en un documento con el número de documentos:\n",
    "\n",
    "\n",
    "$$\n",
    "\\textsf{TF-IDF} = \\textsf{TF}(\\textsf{termino}, \\textsf{documento}) \\times \\textsf{IDF}(\\textsf{termino})\n",
    "$$\n",
    "\n",
    "donde $\\textsf{TF}$ es la frecuencia del término en un documento específico y $\\textsf{IDF}$\n",
    "\n",
    "$$\n",
    "\\textsf{log}\\frac{1 + \\textsf{Numero de documentos}}{1 + \\textsf{DF}} + 1\n",
    "$$\n",
    "\n",
    "donde $\\textsf{DF}$ representa la frecuencia del documento asociado con un término específico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "letras_tfidf = tfidf_vect.fit_transform(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['al', 'coco', 'cono', 'me', 'nena', 'no', 'subas', 'te']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38313051, 0.38313051, 0.        , 0.19156526, 0.09578263,\n",
       "        0.76626103, 0.19156526, 0.19156526],\n",
       "       [0.37099112, 0.37099112, 0.        , 0.09274778, 0.04637389,\n",
       "        0.83473001, 0.09274778, 0.09274778],\n",
       "       [0.38911653, 0.2918374 , 0.1864151 , 0.19455826, 0.09727913,\n",
       "        0.77823306, 0.19455826, 0.19455826],\n",
       "       [0.37099112, 0.37099112, 0.        , 0.09274778, 0.04637389,\n",
       "        0.83473001, 0.09274778, 0.09274778]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letras_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_tfidf = pd.DataFrame(letras_tfidf.toarray())\n",
    "demo_tfidf.columns = tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>al</th>\n",
       "      <th>coco</th>\n",
       "      <th>cono</th>\n",
       "      <th>me</th>\n",
       "      <th>nena</th>\n",
       "      <th>no</th>\n",
       "      <th>subas</th>\n",
       "      <th>te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.383131</td>\n",
       "      <td>0.383131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191565</td>\n",
       "      <td>0.095783</td>\n",
       "      <td>0.766261</td>\n",
       "      <td>0.191565</td>\n",
       "      <td>0.191565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.370991</td>\n",
       "      <td>0.370991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092748</td>\n",
       "      <td>0.046374</td>\n",
       "      <td>0.834730</td>\n",
       "      <td>0.092748</td>\n",
       "      <td>0.092748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.389117</td>\n",
       "      <td>0.291837</td>\n",
       "      <td>0.186415</td>\n",
       "      <td>0.194558</td>\n",
       "      <td>0.097279</td>\n",
       "      <td>0.778233</td>\n",
       "      <td>0.194558</td>\n",
       "      <td>0.194558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.370991</td>\n",
       "      <td>0.370991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092748</td>\n",
       "      <td>0.046374</td>\n",
       "      <td>0.834730</td>\n",
       "      <td>0.092748</td>\n",
       "      <td>0.092748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         al      coco      cono        me      nena        no     subas  \\\n",
       "0  0.383131  0.383131  0.000000  0.191565  0.095783  0.766261  0.191565   \n",
       "1  0.370991  0.370991  0.000000  0.092748  0.046374  0.834730  0.092748   \n",
       "2  0.389117  0.291837  0.186415  0.194558  0.097279  0.778233  0.194558   \n",
       "3  0.370991  0.370991  0.000000  0.092748  0.046374  0.834730  0.092748   \n",
       "\n",
       "         te  \n",
       "0  0.191565  \n",
       "1  0.092748  \n",
       "2  0.194558  \n",
       "3  0.092748  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_strings(string_array):\n",
    "    # ingresamos stopwords y stemmer\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    # con el stemmer reducimos las palabras a una raíz semántica común.\n",
    "    stemmer = nltk.stem.snowball.SnowballStemmer(\"english\")\n",
    "    # holder de strings a nivel de array\n",
    "    string_array_holder = []\n",
    "    # por cada string en el array\n",
    "    for string in string_array:\n",
    "        # holder de palabras en cada string\n",
    "        string_holder = []\n",
    "        # separamos (tokenizamos) cada palabra en el string\n",
    "        tokenized_strings = nltk.word_tokenize(string)\n",
    "        # por cada palabra en el string\n",
    "        for token in tokenized_strings:\n",
    "            # lowercase\n",
    "            token = token.lower()\n",
    "            # reemplazamos todo caracter noalfanumérico a nada.\n",
    "            token = re.sub(re.compile(\"[^A-Za-z0-9]+\"), \"\", token)\n",
    "            # si la palabra no es vacía y no se encuentra a nivel de stopwords\n",
    "            if token != \"\" and token not in stopwords:\n",
    "                # reducimos a la raíz semántica\n",
    "                token = stemmer.stem(token)\n",
    "            # si es que es válida\n",
    "            if token != \"\":\n",
    "                # concatenamos\n",
    "                string_holder.append(token)\n",
    "        # concatenamos a nivel de holders\n",
    "        string_array_holder.append(string_holder)\n",
    "    # devolvemos\n",
    "    \n",
    "    return string_array_holder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementos a considerar en el preprocesamiento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
